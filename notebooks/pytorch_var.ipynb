{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(df, target_name):\n",
    "    return df.drop(target_name, axis=1), df[target_name]\n",
    "\n",
    "def drop_correlated_features(df, threshold):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    df = df.drop(to_drop, axis=1)\n",
    "    return df\n",
    "\n",
    "def drop_min_rows(df, *values):\n",
    "    for value in values:\n",
    "        df = df.drop(df[df['DP'] == value].index, axis=0)\n",
    "    return df\n",
    "\n",
    "def balance_classes(df):\n",
    "    df_balanced = pd.DataFrame()\n",
    "    min_class_count = df['DP'].value_counts().min()\n",
    "    for label in df['DP'].unique():\n",
    "        df_label = df[df['DP'] == label]\n",
    "        if len(df_label) > min_class_count:\n",
    "            df_random_sample = df_label.sample(min_class_count)\n",
    "            df_balanced = pd.concat([df_balanced, df_random_sample])\n",
    "        else:\n",
    "            df_balanced = pd.concat([df_balanced, df_label])\n",
    "    return df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop duplicates\n",
      "drop constant features =  1361\n",
      "split features and target\n",
      "[ True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      " False  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True False  True False  True  True  True  True  True\n",
      "  True False False  True  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True False  True  True  True  True  True False  True  True\n",
      " False  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True]\n",
      "Disbalance 1.00541812323532\n",
      "ON_LINE gen 2 0.050030890874884104\n",
      "ON_LINE gen 3 0.10066834774831124\n",
      "PG gen 3 0.12468731527156685\n",
      "QG gen 3 0.12035612319488642\n",
      "PG gen 5 0.8627950099197041\n",
      "PG gen 11 0.5957531274761709\n",
      "QG gen 11 0.7719104472375553\n",
      "PG gen 12 0.7510667502489956\n",
      "QG gen 26 0.3040920054985863\n",
      "PG gen 27 0.34513288547111376\n",
      "QG gen 27 0.4420522578538386\n",
      "U node 7001 0.7016100483505343\n",
      "FAZA node 7001 0.7779952711952067\n",
      "PN node 7001 0.5827279601077779\n",
      "QN node 7001 0.6766100733208429\n",
      "U node 7003 0.6940311820385312\n",
      "FAZA node 7003 0.8246947095599613\n",
      "QN node 7005 0.6302196795660191\n",
      "PN node 7008 0.3657881596609429\n",
      "QN node 7009 0.5972329798385034\n",
      "PN node 7010 0.6731557918379671\n",
      "QN node 7010 0.6403029994018423\n",
      "QN node 7011 0.3617458573741472\n",
      "U node 7012 0.5433423822568881\n",
      "FAZA node 7012 0.7028127130034025\n",
      "U node 7015 0.5863975153174101\n",
      "FAZA node 7015 0.7491628038639628\n",
      "PN node 7015 0.615902301964484\n",
      "QN node 7015 0.47587646071906975\n",
      "PN node 7016 0.4821832408160829\n",
      "QN node 7016 0.06578104884396163\n",
      "QN node 7019 0.6534336409671113\n",
      "QN node 7023 0.4313012026947818\n",
      "QN node 7025 0.6379295149528272\n",
      "FAZA node 7027 0.7398364638387123\n",
      "QN node 7029 0.40857014284081883\n",
      "PN node 7030 0.4843504159794043\n",
      "QN node 7030 0.468339992065834\n",
      "U node 7032 0.7810526865942018\n",
      "QN node 7032 0.41624832952826285\n",
      "QN node 7033 0.38050938250801414\n",
      "QN node 7034 0.066927953099019\n",
      "PN node 7035 0.7837669208822671\n",
      "QN node 7038 0.4744327311633372\n",
      "PN node 7039 0.21267793493343312\n",
      "QN node 7042 0.15350090791135207\n",
      "QN node 7043 0.643199620160491\n",
      "QN node 7044 0.4608872878504273\n",
      "QN node 7053 0.4627516606690645\n",
      "QN node 7056 0.782223485497719\n",
      "QN node 7057 0.16294244949805448\n",
      "PN node 7059 0.677334369434637\n",
      "QN node 7059 0.5211359511565956\n",
      "PN node 7064 0.46113074301773316\n",
      "PN node 7065 0.6677249607729074\n",
      "QN node 7065 0.3974525757827161\n",
      "PN node 7066 0.7194451269830866\n",
      "QN node 7067 0.6935264476045884\n",
      "PN node 7068 0.5471591573055297\n",
      "QN node 7068 0.3869062463969035\n",
      "PN node 7073 0.5563235246960856\n",
      "QN node 7073 0.6681831060288694\n",
      "PN node 7076 0.6239050755781481\n",
      "QN node 7076 0.3004492427991261\n",
      "PN node 7077 0.15142895260918454\n",
      "PN node 7080 0.6677807319733904\n",
      "QN node 7080 0.7664116579990927\n",
      "QN node 7081 0.8504883169445623\n",
      "PN node 7084 0.3620595189703133\n",
      "QN node 7084 0.5778861221470528\n",
      "QN node 7085 0.050590829289471895\n",
      "QN node 7087 0.11282350057635027\n",
      "QN node 7088 0.6714980132525776\n",
      "QN node 7090 0.5320392796621143\n",
      "PN node 7091 0.23720786567330476\n",
      "QN node 7091 0.6620601472751213\n",
      "QN node 7098 0.4695808580593368\n",
      "QN node 7100 0.5855660247700665\n",
      "QN node 7101 0.5282626566419026\n",
      "QN node 7104 0.7658766130852908\n",
      "QN node 7108 0.079614943102293\n",
      "QN node 7109 0.5965162413649703\n",
      "QN node 7111 0.058470266234679436\n",
      "PN node 7114 0.5439847326752194\n",
      "QN node 7114 0.1402189146310775\n",
      "PN node 7115 0.09515300728811082\n",
      "QN node 7115 0.1256001271319418\n",
      "QN node 7121 0.13819483021987677\n",
      "PN node 7129 0.7041779889391195\n",
      "QN node 7130 0.630345484083185\n",
      "PN node 7135 0.40169429832462766\n",
      "PN node 7141 0.5213013861382594\n",
      "QN node 7141 0.43564734470161426\n",
      "QN node 7142 0.42409432362325905\n",
      "PN node 7146 0.6109245774066201\n",
      "PN node 7147 0.17310447590632982\n",
      "QN node 7147 0.09149760868025059\n",
      "QN node 7223 0.09806354904758541\n",
      "U node 7243 0.5825179241735601\n",
      "QN node 7243 0.5363485772087817\n",
      "QN node 7244 0.49389278314762697\n",
      "U node 7260 0.7419132907163384\n",
      "FAZA node 7302 0.2432415374613326\n",
      "FAZA node 7602 0.6952839962325752\n",
      "QN node 7611 0.600704426325197\n",
      "U node 7710 0.6423454438953768\n",
      "PN node 7712 0.4617954407061975\n",
      "QN node 7712 0.32127378320816913\n",
      "PN node 7714 0.5547925339076518\n",
      "QN node 7714 0.4603940738191623\n",
      "PN node 7718 0.6406702249468241\n",
      "QN node 7719 0.15385668896575222\n",
      "QN node 7720 0.0644473363814062\n",
      "QN node 7774 0.40600874577466994\n",
      "QN node 7776 0.7021006754267216\n",
      "QN node 7811 0.46532442527801776\n",
      "QN node 7819 0.10940622361556063\n",
      "QN node 7820 0.10817465167952767\n",
      "PN node 7822 0.5364461967867802\n",
      "PN node 7829 0.39521926747688063\n",
      "PN node 7830 0.3830133064538015\n",
      "QN node 7955 0.5020576107016659\n",
      "PN node 7956 0.42104883852695973\n",
      "PN node 7957 0.39111422721012445\n",
      "I_BEG line 5 0.803679557300008\n",
      "Q_BEG line 7 0.47208751975263663\n",
      "P_BEG line 8 0.6858726882042414\n",
      "Q_BEG line 8 0.5471716334737478\n",
      "P_BEG line 10 0.5680024622235487\n",
      "I_BEG line 11 0.7906502300024221\n",
      "Q_BEG line 12 0.7154787598147929\n",
      "I_END line 12 0.7254033906925901\n",
      "Q_BEG line 16 0.4912852177017153\n",
      "Q_BEG line 18 0.5595996085025878\n",
      "I_BEG line 21 0.7040743127034559\n",
      "I_END line 22 0.6447551839630876\n",
      "P_BEG line 23 0.34616176842234836\n",
      "I_BEG line 23 0.3673507941310903\n",
      "I_BEG line 25 0.3710002357488702\n",
      "Q_BEG line 26 0.5279947454448295\n",
      "Q_BEG line 36 0.6796965978327565\n",
      "Q_BEG line 40 0.4502452335317011\n",
      "Q_BEG line 42 0.4125106279834365\n",
      "Q_BEG line 45 0.25364060581163805\n",
      "Q_BEG line 46 0.6013391086955802\n",
      "P_BEG line 50 0.5663001002467631\n",
      "Q_BEG line 50 0.33465992095492014\n",
      "P_BEG line 52 0.40272252869459146\n",
      "Q_BEG line 52 0.134518395765181\n",
      "Q_BEG line 57 0.4607561439348016\n",
      "P_BEG line 60 0.516888771025565\n",
      "Q_BEG line 60 0.6719800803411553\n",
      "P_BEG line 64 0.3217245584514479\n",
      "P_BEG line 66 0.412569095087187\n",
      "Q_BEG line 68 0.7540297422532214\n",
      "Q_BEG line 71 0.4468650038721884\n",
      "P_BEG line 73 0.6477229435758949\n",
      "P_BEG line 75 0.33527804554068474\n",
      "P_BEG line 77 0.05197635053300331\n",
      "Q_BEG line 78 0.5086871149933712\n",
      "P_BEG line 85 0.6097292549170525\n",
      "Q_BEG line 85 0.4871875448168168\n",
      "I_BEG line 85 0.571674349847052\n",
      "Q_BEG line 90 0.15104437930157477\n",
      "Q_BEG line 95 0.7110418667092608\n",
      "I_BEG line 95 0.6200871266076653\n",
      "Q_BEG line 99 0.14909628838332\n",
      "I_BEG line 99 0.7890278704327904\n",
      "Q_BEG line 101 0.6839027581068651\n",
      "Q_BEG line 110 0.5846318097851708\n",
      "I_BEG line 111 0.47358913115198553\n",
      "Q_BEG line 121 0.32815075138122385\n",
      "Q_END line 126 0.6471639860043255\n",
      "Q_BEG line 131 0.14252574104651083\n",
      "I_BEG line 144 0.7086878803858339\n",
      "Q_BEG line 159 0.37309857701147386\n",
      "Q_BEG line 165 0.6242537468109528\n",
      "Q_BEG line 166 0.761276731248091\n",
      "Q_BEG line 168 0.5912167961355626\n",
      "I_END line 168 0.5505238212269561\n",
      "Q_BEG line 178 0.5627997051484843\n",
      "Q_END line 181 0.05118850519802498\n",
      "P_BEG line 187 0.43357156135747577\n",
      "I_BEG line 187 0.5169894874860721\n",
      "P_BEG line 188 0.5358635211593774\n",
      "Q_BEG line 191 0.6219471648392207\n",
      "Q_BEG line 198 0.5919203977278098\n",
      "Q_BEG line 200 0.5170621531875774\n",
      "Q_END line 200 0.5599904435522924\n",
      "Q_BEG line 206 0.10461661913001707\n",
      "Q_END line 206 0.21370011502100894\n",
      "Q_BEG line 208 0.5484427767041853\n",
      "P_BEG line 220 0.1311454511561858\n",
      "I_BEG line 220 0.16123600971247098\n",
      "Q_BEG line 300 0.7176121925904142\n",
      "Q_BEG line 310 0.5381605358247865\n",
      "I_END line 312 0.2770194958998662\n",
      "P_BEG line 317 0.15301164670759837\n",
      "I_END line 317 0.24359360791885498\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disbalance</th>\n",
       "      <th>ON_LINE gen 2</th>\n",
       "      <th>ON_LINE gen 3</th>\n",
       "      <th>PG gen 3</th>\n",
       "      <th>QG gen 3</th>\n",
       "      <th>PG gen 5</th>\n",
       "      <th>PG gen 11</th>\n",
       "      <th>QG gen 11</th>\n",
       "      <th>PG gen 12</th>\n",
       "      <th>QG gen 26</th>\n",
       "      <th>...</th>\n",
       "      <th>Q_BEG line 206</th>\n",
       "      <th>Q_END line 206</th>\n",
       "      <th>Q_BEG line 208</th>\n",
       "      <th>P_BEG line 220</th>\n",
       "      <th>I_BEG line 220</th>\n",
       "      <th>Q_BEG line 300</th>\n",
       "      <th>Q_BEG line 310</th>\n",
       "      <th>I_END line 312</th>\n",
       "      <th>P_BEG line 317</th>\n",
       "      <th>I_END line 317</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.05</td>\n",
       "      <td>6.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>142.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.66</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>142.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.17</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>143.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.17</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>142.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.78</td>\n",
       "      <td>7.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Disbalance  ON_LINE gen 2  ON_LINE gen 3  PG gen 3  QG gen 3  PG gen 5  \\\n",
       "5       143.14              0              0       0.0       0.0       0.0   \n",
       "15      142.77              0              0       0.0       0.0       0.0   \n",
       "16      142.60              0              0       0.0       0.0       0.0   \n",
       "18      143.20              0              0       0.0       0.0       0.0   \n",
       "19      142.49              0              0       0.0       0.0       0.0   \n",
       "\n",
       "    PG gen 11  QG gen 11  PG gen 12  QG gen 26  ...  Q_BEG line 206  \\\n",
       "5       68.05       6.88        0.0        0.0  ...           -0.47   \n",
       "15      67.66       7.02        0.0        0.0  ...           -0.47   \n",
       "16      68.17       7.14        0.0        0.0  ...           -0.47   \n",
       "18      68.17       7.07        0.0        0.0  ...           -0.47   \n",
       "19      67.78       7.12        0.0        0.0  ...           -0.47   \n",
       "\n",
       "    Q_END line 206  Q_BEG line 208  P_BEG line 220  I_BEG line 220  \\\n",
       "5              0.5            0.13             0.0             0.0   \n",
       "15             0.5            0.13             0.0             0.0   \n",
       "16             0.5            0.13             0.0             0.0   \n",
       "18             0.5            0.14             0.0             0.0   \n",
       "19             0.5            0.13             0.0             0.0   \n",
       "\n",
       "    Q_BEG line 300  Q_BEG line 310  I_END line 312  P_BEG line 317  \\\n",
       "5            -0.39            3.38             0.0            0.81   \n",
       "15           -0.38            3.34             0.0            0.49   \n",
       "16           -0.40            3.39             0.0            0.00   \n",
       "18           -0.38            3.38             0.0            0.00   \n",
       "19           -0.39            3.38             0.0            0.00   \n",
       "\n",
       "    I_END line 317  \n",
       "5             3.98  \n",
       "15            2.44  \n",
       "16            0.28  \n",
       "18            0.28  \n",
       "19            0.28  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from posixpath import split\n",
    "# load dataset\n",
    "\n",
    "df = pd.read_csv(\"Data.csv\", header = 0, delimiter = \";\")\n",
    "print(\"drop duplicates\")\n",
    "df = df.drop_duplicates()\n",
    "constant_features = [column for column in df.columns if df[column].nunique() == 1]\n",
    "print(\"drop constant features = \",len(constant_features))\n",
    "df.drop(columns=constant_features, inplace=True)\n",
    "print(\"split features and target\")\n",
    "\n",
    "df_features, df_target = get_target(df, 'DP')\n",
    "\n",
    "df_corr = drop_correlated_features(df_features, 0.9)\n",
    "\n",
    "df = pd.concat([df_corr, df_target], axis=1)\n",
    "new_df = drop_min_rows(df, -60, -140)\n",
    "\n",
    "#new_df = balance_classes(new_df)\n",
    "\n",
    "df_check = new_df.copy()\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif, chi2\n",
    "\n",
    "kbest = SelectKBest(k=200, score_func=mutual_info_classif)\n",
    "kbest.fit(df_check.drop('DP', axis=1), df_check['DP'])\n",
    "rec = kbest.get_support()\n",
    "print(rec)\n",
    "list_best = []\n",
    "for i, r in enumerate(rec):\n",
    "    if r == True:\n",
    "        list_best.append(df_check.columns[i])\n",
    "        print(df_check.columns[i], kbest.scores_[i])\n",
    "if 'DP' in list_best:\n",
    "    list_best.remove('DP')\n",
    "df_best = df_check[list_best]\n",
    "\n",
    "# check that dataframe contain column\n",
    "\n",
    "if df_best.Disbalance.empty == None:\n",
    "    df_best =  pd.concat([df_check.Disbalance, df_best], axis=1)\n",
    "\n",
    "df_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test features: 94.23076923076923 %\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=200, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc5): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc7): Linear(in_features=64, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# pytorch multiclass classification\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_labels = df_check[\"DP\"]\n",
    "data_labels = pd.factorize(data_labels)[0]\n",
    "data_features = df_best\n",
    "\n",
    "# pytorch model\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(data_features, data_labels, test_size = 0.2, random_state = 42)\n",
    "\n",
    "train_features = torch.from_numpy(train_features.values).float()\n",
    "\n",
    "test_features = torch.from_numpy(test_features.values).float()\n",
    "\n",
    "train_labels = torch.from_numpy(train_labels).long()\n",
    "\n",
    "test_labels = torch.from_numpy(test_labels).long()\n",
    "\n",
    "train = Dataset(train_features, train_labels)\n",
    "\n",
    "test = Dataset(test_features, test_labels)\n",
    "\n",
    "train_loader = DataLoader(dataset = train, batch_size = 64, shuffle = True)\n",
    "\n",
    "test_loader = DataLoader(dataset = test, batch_size = 64, shuffle = True)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 64)\n",
    "        #self.fc6 = nn.Linear(64, 64)\n",
    "        self.fc7 = nn.Linear(64, output_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        #x = F.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(data_features.shape[1], 6)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for test_features, test_labels in test_loader:\n",
    "        outputs = model(test_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += test_labels.size(0)\n",
    "        correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test features: {} %'.format(100 * correct / total))\n",
    "\n",
    "\n",
    "\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
